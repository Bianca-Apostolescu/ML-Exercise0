{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2024-01-20T20:57:31.004353Z",
          "iopub.status.busy": "2024-01-20T20:57:31.003518Z",
          "iopub.status.idle": "2024-01-20T20:57:57.545570Z",
          "shell.execute_reply": "2024-01-20T20:57:57.544650Z",
          "shell.execute_reply.started": "2024-01-20T20:57:31.004312Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "trusted": true,
        "id": "Ia5tFr8nDJ4V"
      },
      "outputs": [],
      "source": [
        "#!pip install accelerate -U\n",
        "#!pip install transformers -U\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "#!pip install datasets\n",
        "from datasets import load_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-20T20:58:02.624236Z",
          "iopub.status.busy": "2024-01-20T20:58:02.622848Z",
          "iopub.status.idle": "2024-01-20T20:58:04.285713Z",
          "shell.execute_reply": "2024-01-20T20:58:04.284915Z",
          "shell.execute_reply.started": "2024-01-20T20:58:02.624190Z"
        },
        "id": "JMfEJ6yQUErX",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "datapath = \"/content/drive/MyDrive/NewsDataset.csv\"\n",
        "train_dataset = load_dataset(\"csv\", data_files= datapath, split=\"train[:70%]\")\n",
        "test_dataset = load_dataset(\"csv\", data_files= datapath, split=\"train[70%:90%]\")\n",
        "valid_dataset = load_dataset(\"csv\", data_files= datapath, split=\"train[90%:]\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-20T20:58:27.946286Z",
          "iopub.status.busy": "2024-01-20T20:58:27.945918Z",
          "iopub.status.idle": "2024-01-20T20:58:34.969115Z",
          "shell.execute_reply": "2024-01-20T20:58:34.968103Z",
          "shell.execute_reply.started": "2024-01-20T20:58:27.946256Z"
        },
        "id": "WQagXjQIPfFh",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3558993-6ff7-4136-8daa-4e4724eba666"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilgpt2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2024-01-20T22:47:58.170385Z",
          "iopub.status.busy": "2024-01-20T22:47:58.169997Z",
          "iopub.status.idle": "2024-01-20T22:48:06.844872Z",
          "shell.execute_reply": "2024-01-20T22:48:06.843548Z",
          "shell.execute_reply.started": "2024-01-20T22:47:58.170354Z"
        },
        "id": "LHnZgC0rPfDr",
        "jupyter": {
          "outputs_hidden": true
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def preprocess_function(examples):\n",
        "    return tokenizer(examples[\"text\"])\n",
        "\n",
        "def tokenize(dataset):\n",
        "  tokenized_news = dataset.map(preprocess_function, batched=True,\n",
        "      num_proc=2, remove_columns=dataset.column_names)\n",
        "  return tokenized_news\n",
        "\n",
        "train_dataset_tokenized = tokenize(train_dataset)\n",
        "test_dataset_tokenized = tokenize(test_dataset)\n",
        "valid_dataset_tokenized = tokenize(valid_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-20T22:49:20.608733Z",
          "iopub.status.busy": "2024-01-20T22:49:20.608274Z",
          "iopub.status.idle": "2024-01-20T22:49:31.507060Z",
          "shell.execute_reply": "2024-01-20T22:49:31.505718Z",
          "shell.execute_reply.started": "2024-01-20T22:49:20.608700Z"
        },
        "id": "IjqoERYePfB3",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "block_size = 128\n",
        "def group_texts(examples):\n",
        "    # Concatenate all texts.\n",
        "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
        "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
        "    if total_length >= block_size:\n",
        "        total_length = (total_length // block_size) * block_size\n",
        "    # Split by chunks of block_size.\n",
        "    result = {\n",
        "        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n",
        "        for k, t in concatenated_examples.items()\n",
        "    }\n",
        "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
        "    return result\n",
        "\n",
        "lm_dataset_train = train_dataset_tokenized.map(group_texts, batched=True, num_proc=6)\n",
        "lm_dataset_test = test_dataset_tokenized.map(group_texts, batched=True, num_proc=6)\n",
        "lm_dataset_valid = valid_dataset_tokenized.map(group_texts, batched=True, num_proc=6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-20T22:49:31.510781Z",
          "iopub.status.busy": "2024-01-20T22:49:31.510329Z",
          "iopub.status.idle": "2024-01-20T22:49:31.521622Z",
          "shell.execute_reply": "2024-01-20T22:49:31.516501Z",
          "shell.execute_reply.started": "2024-01-20T22:49:31.510740Z"
        },
        "id": "-L-8CrMePe-e",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from transformers import DataCollatorForLanguageModeling\n",
        "#Use the end-of-sequence token as the padding token and set mlm=False.\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-20T22:49:31.523637Z",
          "iopub.status.busy": "2024-01-20T22:49:31.523214Z",
          "iopub.status.idle": "2024-01-20T22:49:32.417682Z",
          "shell.execute_reply": "2024-01-20T22:49:32.416546Z",
          "shell.execute_reply.started": "2024-01-20T22:49:31.523601Z"
        },
        "id": "QEIt8dE2Pe8Z",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForCausalLM, TrainingArguments, Trainer\n",
        "access_token = \"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\"\n",
        "model = AutoModelForCausalLM.from_pretrained(\"distilgpt2\", token=access_token)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-20T22:49:58.895306Z",
          "iopub.status.busy": "2024-01-20T22:49:58.894444Z",
          "iopub.status.idle": "2024-01-20T23:01:55.481768Z",
          "shell.execute_reply": "2024-01-20T23:01:55.480135Z",
          "shell.execute_reply.started": "2024-01-20T22:49:58.895273Z"
        },
        "id": "cZMCz9MBXG6j",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"news_clm-model\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    weight_decay=0.01,\n",
        "    num_train_epochs = 2,\n",
        "    per_device_train_batch_size = 20,\n",
        "    per_device_eval_batch_size=8,\n",
        "    eval_accumulation_steps=16,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=lm_dataset_train,\n",
        "    eval_dataset=lm_dataset_test,\n",
        "    data_collator=data_collator\n",
        ")\n",
        "\n",
        "#trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-20T21:34:34.424679Z",
          "iopub.status.busy": "2024-01-20T21:34:34.423984Z",
          "iopub.status.idle": "2024-01-20T21:37:06.552942Z",
          "shell.execute_reply": "2024-01-20T21:37:06.551446Z",
          "shell.execute_reply.started": "2024-01-20T21:34:34.424643Z"
        },
        "id": "KsZsTNnmPe6C",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "356c740e-56a8-4796-fa25-31085bf43cf3"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='370' max='370' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [370/370 00:21]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Perplexity: 44.26\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "eval_results = trainer.evaluate()\n",
        "print(f\"Perplexity: {math.exp(eval_results['eval_loss']):.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-20T23:20:49.544371Z",
          "iopub.status.busy": "2024-01-20T23:20:49.543849Z",
          "iopub.status.idle": "2024-01-20T23:20:50.879176Z",
          "shell.execute_reply": "2024-01-20T23:20:50.877848Z",
          "shell.execute_reply.started": "2024-01-20T23:20:49.544335Z"
        },
        "trusted": true,
        "id": "GHkG6Rk8DJ4d",
        "outputId": "fe3a8abe-1cd8-48df-8b54-b3d2b846be1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tar: Removing leading `/' from member names\n",
            "/kaggle/working/model/news_clm-model/\n",
            "/kaggle/working/model/news_clm-model/config.json\n",
            "/kaggle/working/model/news_clm-model/training_args.bin\n",
            "/kaggle/working/model/news_clm-model/model.safetensors\n",
            "/kaggle/working/model/news_clm-model/generation_config.json\n"
          ]
        }
      ],
      "source": [
        " #trainer.save_model(\"/kaggle/working/model/news_clm-model\")\n",
        "#!tar cvf fine-tuned-model.tar.gz /kaggle/working/model/news_clm-model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RGU9iXSDJ4e"
      },
      "source": [
        "## Exemples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2024-01-20T23:30:40.220859Z",
          "iopub.status.busy": "2024-01-20T23:30:40.220111Z",
          "iopub.status.idle": "2024-01-20T23:30:40.397183Z",
          "shell.execute_reply": "2024-01-20T23:30:40.396125Z",
          "shell.execute_reply.started": "2024-01-20T23:30:40.220821Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "trusted": true,
        "id": "MimL2Xh9DJ4f"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForCausalLM\n",
        "model = AutoModelForCausalLM.from_pretrained(\"/content/drive/MyDrive/news_clm-model\") # <path_to_saved_model>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-20T23:10:30.366526Z",
          "iopub.status.busy": "2024-01-20T23:10:30.365988Z",
          "iopub.status.idle": "2024-01-20T23:10:30.539487Z",
          "shell.execute_reply": "2024-01-20T23:10:30.538520Z",
          "shell.execute_reply.started": "2024-01-20T23:10:30.366488Z"
        },
        "id": "FdzYysppXXUR",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "from transformers import AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilgpt2\")\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "generator = pipeline(\"text-generation\", model= model, tokenizer= tokenizer, device =\"cuda\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "#!pip install rouge\n",
        "#!pip install rouge_score\n",
        "from rouge import Rouge\n",
        "from rouge_score import rouge_scorer\n",
        "import nltk\n",
        "import re\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "5Qob9NlBg0hy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validset_preparation(min_word_count=5, max_word_count=20):\n",
        "  sentences = []\n",
        "  labels = []\n",
        "  for text in valid_dataset['text']:\n",
        "    sentence = nltk.sent_tokenize(text)\n",
        "    word_pattern = re.compile(r'\\b\\w+\\b')\n",
        "\n",
        "    for phrase in sentence:\n",
        "      phrase_split = word_pattern.findall(phrase)\n",
        "      if min_word_count <= len(phrase_split) <= max_word_count:\n",
        "        sentences.append(' '.join(phrase_split[:-1]))\n",
        "        label = phrase_split[-1:]\n",
        "        labels.append(label)\n",
        "  return sentences, labels\n",
        "\n",
        "sentences, labels = validset_preparation()"
      ],
      "metadata": {
        "id": "-rsZvDaovT62"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict= []\n",
        "bleu_scores = []\n",
        "rouge_1_scores= []\n",
        "rouge_2_scores= []\n",
        "rouge_l_scores= []\n",
        "\n",
        "import logging\n",
        "logging.getLogger(\"transformers.tokenization_utils_base\").setLevel(logging.WARNING)\n",
        "\n",
        "for sentence in sentences:\n",
        "  text = generator(sentence, num_return_sequences=1, return_full_text=False)\n",
        "  predict_word = text[0]['generated_text'].split()[0]\n",
        "  predict.append(predict_word)\n",
        "\n",
        "  bleu_score = sentence_bleu(sentence, predict_word)\n",
        "  bleu_score = round(bleu_score, 4)\n",
        "  bleu_scores.append(bleu_score)"
      ],
      "metadata": {
        "id": "98WdSsd5u0_L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qfd7QHrOl4aA"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "datasetId": 4332564,
          "sourceId": 7443477,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 4332582,
          "sourceId": 7443507,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30636,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}